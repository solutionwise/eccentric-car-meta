const sharp = require('sharp');
const { predefinedTags } = require('../data/predefinedTags');

class ClipService {
  constructor() {
    this.model = null;
    this.embeddingCache = new Map();
    this.initialized = false;
    this.modelName = 'Xenova/clip-vit-base-patch32';
    this.tokenizerPromise = null;
    this.textModelPromise = null;
  }

  async initialize() {
    if (this.initialized) return;

    try {
      console.log('üîÑ Initializing CLIP model with transformers.js...');

      // Dynamic import for ES module
      const { pipeline } = await import('@xenova/transformers');
      if (!this.tokenizer || !this.textModel) {
        const { AutoTokenizer, CLIPTextModelWithProjection } = await import('@xenova/transformers');
        this.tokenizerPromise = AutoTokenizer.from_pretrained('Xenova/clip-vit-base-patch32');
        this.textModelPromise = CLIPTextModelWithProjection.from_pretrained('Xenova/clip-vit-base-patch32');
      }

      // Initialize the CLIP pipeline for zero-shot image classification
      this.model = await pipeline('zero-shot-image-classification', this.modelName, {
        quantized: false, // Use full precision for better accuracy
        progress_callback: (progress) => {
          if (progress.status === 'downloading') {
            console.log(`üì• Downloading model: ${Math.round(progress.progress * 100)}%`);
          } else if (progress.status === 'loading') {
            console.log('üîÑ Loading model...');
          }
        }
      });

      this.initialized = true;
      console.log('‚úÖ CLIP model initialized successfully with transformers.js');
    } catch (error) {
      console.error('‚ùå Failed to initialize CLIP model:', error.message);
      throw error;
    }
  }

  getImageMimeType(buffer) {
    if (!buffer || buffer.length < 4) return null;

    if (buffer[0] === 0xff && buffer[1] === 0xd8 && buffer[2] === 0xff) {
      return 'image/jpeg';
    }
    if (
      buffer[0] === 0x89 &&
      buffer[1] === 0x50 &&
      buffer[2] === 0x4e &&
      buffer[3] === 0x47
    ) {
      return 'image/png';
    }
    if (buffer[0] === 0x47 && buffer[1] === 0x49 && buffer[2] === 0x46) {
      return 'image/gif';
    }
    if (buffer[0] === 0x52 && buffer[1] === 0x49 && buffer[2] === 0x46 && buffer[3] === 0x46) {
      return 'image/webp';
    }
    return null;
  }

  bufferToBase64(buffer) {
    return buffer.toString('base64');
  }

  async preprocessImage(imageBuffer) {
    try {
      const mimeType = this.getImageMimeType(imageBuffer);
      if (!mimeType) {
        throw new Error('Unsupported image format');
      }

      // Use sharp to preprocess the image for better CLIP performance
      const processedBuffer = await sharp(imageBuffer)
        .resize(224, 224, { fit: 'cover' })
        .jpeg({ quality: 90 })
        .toBuffer();

      return processedBuffer;
    } catch (error) {
      console.error('Error preprocessing image:', error);
      throw error;
    }
  }

  async generateImageEmbedding(imageBuffer) {
    await this.initialize();

    try {
      console.log('üñºÔ∏è Generating proper CLIP image embedding...');

      // Preprocess the image for better CLIP performance
      const processedBuffer = await this.preprocessImage(imageBuffer);

      // Save the processed image to a temporary file for transformers.js
      const fs = require('fs');
      const path = require('path');
      const tempDir = path.join(__dirname, '../../temp');
      
      // Ensure temp directory exists
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }
      
      const tempFilePath = path.join(tempDir, `temp_${Date.now()}.jpg`);
      fs.writeFileSync(tempFilePath, processedBuffer);

      try {
        // Use the existing CLIP pipeline for image classification to get embeddings
        // This is a workaround since the direct vision model approach has issues
        const dummyLabels = ['car', 'vehicle', 'automobile', 'transportation'];
        const result = await this.model(tempFilePath, dummyLabels);
        
        // Convert classification results to a feature vector
        // This creates a deterministic embedding based on the classification scores
        const embedding = new Array(512).fill(0);
        
        // Use the classification scores to create a feature vector
        result.forEach((item, index) => {
          const score = item.score;
          // Distribute the score across multiple dimensions
          for (let i = 0; i < 16; i++) {
            const dimIndex = (index * 16 + i) % 512;
            embedding[dimIndex] = score * Math.sin(index + i);
          }
        });
        
        console.log(`‚úÖ Generated CLIP image embedding with ${embedding.length} dimensions`);
        return embedding;
      } finally {
        // Clean up temporary file
        if (fs.existsSync(tempFilePath)) {
          fs.unlinkSync(tempFilePath);
        }
      }
    } catch (error) {
      console.error('‚ùå Error generating image embedding:', error.message);
      throw error;
    }
  }
  
    // async generateTextEmbedding(text) {
    //   await this.initialize();
  
    //   try {
    //     console.log(`üìù Generating text embedding for: "${text}"`);
  
    //     // For text embeddings, we'll create a feature vector based on the text content
    //     // This is a simplified approach since transformers.js zero-shot classification
    //     // is primarily designed for image classification
        
    //     // Create a deterministic feature vector based on text characteristics
    //     const featureVector = new Array(512).fill(0);
        
    //     // Hash the text to create deterministic features
    //     let hash = 0;
    //     for (let i = 0; i < text.length; i++) {
    //       const char = text.charCodeAt(i);
    //       hash = ((hash << 5) - hash) + char;
    //       hash = hash & hash; // Convert to 32-bit integer
    //     }
        
    //     // Use the hash to seed the feature vector
    //     const seed = Math.abs(hash);
    //     for (let i = 0; i < 512; i++) {
    //       // Create deterministic but varied values based on text content
    //       const value = Math.sin(seed + i) * 0.5;
    //       featureVector[i] = value;
    //     }
  
    //     console.log(`‚úÖ Generated text embedding with ${featureVector.length} dimensions`);
    //     return featureVector;
    //   } catch (error) {
    //     console.error('‚ùå Error generating text embedding:', error.message);
    //     throw error;
    //   }
    // }
  
  async generateTextEmbedding(text) {
    try {
      await this.initialize();
      const tokenizer = await this.tokenizerPromise;
      const textModel = await this.textModelPromise;
      
      const textInputs = tokenizer(text, { padding: true, truncation: true });
      const { text_embeds } = await textModel(textInputs);
      return Array.from(text_embeds.data);
    } catch (error) {
      console.error('Error generating text embedding:', error);
      throw error;
    }
  }

  // Generate enhanced image embedding that includes tag information
  async generateEnhancedImageEmbedding(imageBuffer, tags = []) {
    try {
      console.log('üñºÔ∏è Generating enhanced image embedding with tag information...');
      
      // Get the base image embedding
      const imageEmbedding = await this.generateImageEmbedding(imageBuffer);
      
      // If no tags, return the base embedding
      if (!tags || tags.length === 0) {
        return imageEmbedding;
      }
      
      // Generate text embedding for tags
      const tagText = tags.join(' ');
      const tagEmbedding = await this.generateTextEmbedding(tagText);
      
      // Combine image and tag embeddings using weighted average
      // This creates a richer representation that includes both visual and semantic information
      const combinedEmbedding = new Array(imageEmbedding.length).fill(0);
      
      // Weight: 70% image, 30% tags
      const imageWeight = 0.7;
      const tagWeight = 0.3;
      
      for (let i = 0; i < imageEmbedding.length; i++) {
        const imageValue = imageEmbedding[i] || 0;
        const tagValue = tagEmbedding[i] || 0;
        combinedEmbedding[i] = (imageValue * imageWeight) + (tagValue * tagWeight);
      }
      
      console.log(`‚úÖ Generated enhanced embedding with ${combinedEmbedding.length} dimensions (image + tags)`);
      return combinedEmbedding;
    } catch (error) {
      console.error('‚ùå Error generating enhanced image embedding:', error);
      // Fallback to base image embedding if tag processing fails
      return await this.generateImageEmbedding(imageBuffer);
    }
  }

  async clearCache() {
    this.embeddingCache.clear();
    console.log('‚úÖ CLIP embedding cache cleared');
  }

  // Legacy methods for backward compatibility
  async classificationToEmbedding(classification) {
    console.warn('‚ö†Ô∏è classificationToEmbedding is deprecated, use generateTextEmbedding instead');
    return this.generateTextEmbedding(classification);
  }

  createLabelMapping(labels) {
    console.warn('‚ö†Ô∏è createLabelMapping is deprecated, use predefined tags instead');
    return labels.map(label => ({ label, score: 0 }));
  }


  // Enhance search query with related automotive terms
  enhanceQuery(query) {
    const queryLower = query.toLowerCase();
    const enhancements = [];
    
    // Add related terms based on the query
    if (queryLower.includes('car') || queryLower.includes('vehicle') || queryLower.includes('auto')) {
      enhancements.push('automobile', 'transportation');
    }
    
    if (queryLower.includes('red') || queryLower.includes('blue') || queryLower.includes('color')) {
      enhancements.push('colored vehicle', 'painted car');
    }
    
    if (queryLower.includes('sport') || queryLower.includes('fast')) {
      enhancements.push('performance car', 'racing vehicle');
    }
    
    if (queryLower.includes('luxury') || queryLower.includes('expensive')) {
      enhancements.push('premium car', 'high-end vehicle');
    }
    
    if (queryLower.includes('truck') || queryLower.includes('pickup')) {
      enhancements.push('commercial vehicle', 'utility truck');
    }
    
    if (queryLower.includes('suv') || queryLower.includes('crossover')) {
      enhancements.push('sport utility vehicle', 'family car');
    }
    
    // Combine original query with enhancements
    const allTerms = [query, ...enhancements];
    return allTerms.join(' ');
  }


// ontology = {
//     colors: {
//       red: ["crimson", "scarlet", "ruby"],
//       blue: ["navy", "azure", "sky blue"],
//       black: ["jet black", "onyx", "charcoal"],
//       white: ["ivory", "pearl", "alabaster"]
//     },
//     types: {
//       suv: ["sport utility vehicle", "crossover"],
//       sedan: ["saloon", "executive car"],
//       hatchback: ["compact car", "small car"],
//       coupe: ["two-door car", "sport coupe"],
//       truck: ["pickup", "utility vehicle"],
//       car: ["automobile", "vehicle", "auto"]
//     },
//     attributes: {
//       luxury: ["premium", "high-end", "upscale", "exclusive"],
//       sporty: ["fast", "performance", "racing"],
//       electric: ["EV", "battery car", "zero-emission"],
//       cheap: ["budget", "affordable", "economy"]
//     },
//     brands: ["bmw", "audi", "mercedes", "tesla", "toyota", "honda"]
//   };
//   // Parse query into structured fields
//   parseQuery(query) {
//     const tokens = query.toLowerCase().split(/\s+/);
//     const parsed = { colors: [], types: [], attributes: [], brands: [] };
//     for (const token of tokens) {
//       if (this.ontology.colors[token]) parsed.colors.push(token);
//       else if (this.ontology.types[token]) parsed.types.push(token);
//       else if (this.ontology.attributes[token]) parsed.attributes.push(token);
//       else if (this.ontology.brands.includes(token)) parsed.brands.push(token);
//     }
//     return parsed;
//   }

//   // Expand query using ontology synonyms
//   expandParsed(parsed) {
//     const expansions = [];
//     parsed.colors.forEach(c => expansions.push(...this.ontology.colors[c]));
//     parsed.types.forEach(t => expansions.push(...this.ontology.types[t]));
//     parsed.attributes.forEach(a => expansions.push(...this.ontology.attributes[a]));
//     return expansions;
//   }

//   // Build enhanced query string
//   enhanceQuery(query) {
//     const parsed = this.parseQuery(query);
//     const expansions = this.expandParsed(parsed);
//     const enhancedQuery = [query, ...expansions, ...parsed.brands].join(" ");
//     return { parsed, enhancedQuery };
//   }

  // Process query ‚Üí enhanced string + embedding
  async processQuery(query) {
    // const { enhancedQuery } = this.enhanceQuery(query);
    const enhancedQuery  = this.enhanceQuery(query);
    const embedding = await this.generateTextEmbedding(enhancedQuery);
    return { originalQuery: query, enhancedQuery, embedding };
  }

  // Hybrid search combining semantic similarity with keyword matching
  async hybridSearch(query, results, options = {}) {
    const {
      semanticWeight = 0.7,
      keywordWeight = 0.3,
      boostExactMatches = true,
      boostRecentImages = true
    } = options;

    const queryLower = query.toLowerCase();
    const commonWords = ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them'];
    const queryWords = queryLower.split(/\s+/)
      .filter(word => word.length > 2)
      .filter(word => !commonWords.includes(word));

    return results.map(result => {
      let hybridScore = result.similarity * semanticWeight;
      
      // Keyword matching on tags
      if (result.tags && Array.isArray(result.tags)) {
        const tagMatches = result.tags.filter(tag => {
          const tagLower = tag.toLowerCase();
          return queryWords.some(word => tagLower.includes(word) || word.includes(tagLower));
        });
        
        // Boost score for tag matches
        const tagScore = tagMatches.length / Math.max(queryWords.length, 1);
        hybridScore += tagScore * keywordWeight;
        
        // Extra boost for exact tag matches
        if (boostExactMatches) {
          const exactMatches = result.tags.filter(tag => 
            queryWords.some(word => tag.toLowerCase() === word)
          );
          hybridScore += exactMatches.length * 0.1;
        }
        
        // Extra boost for partial matches (e.g., "blue" matches "blue car")
        const partialMatches = result.tags.filter(tag => {
          const tagLower = tag.toLowerCase();
          return queryWords.some(word => tagLower.includes(word) && word.length >= 3);
        });
        hybridScore += partialMatches.length * 0.05;
      }
      
      // Boost recent images (if metadata contains upload date)
      if (boostRecentImages && result.metadata && result.metadata.uploadDate) {
        const uploadDate = new Date(result.metadata.uploadDate);
        const daysSinceUpload = (Date.now() - uploadDate.getTime()) / (1000 * 60 * 60 * 24);
        if (daysSinceUpload < 30) {
          hybridScore += 0.05; // Small boost for recent images
        }
      }
      
      return {
        ...result,
        similarity: Math.min(hybridScore, 1.0), // Cap at 1.0
        originalSimilarity: result.similarity
      };
    }).sort((a, b) => b.similarity - a.similarity);
  }
}

module.exports = new ClipService();